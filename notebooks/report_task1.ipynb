{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Systems Task 1\n",
    "_Daniel Jones, Praful Chunchu, Ravi Patel and Austin Staton_\n",
    "\n",
    "**Objective**: Generating adversarial attacks in the context of a zero-knowledge threat model.\n",
    "\n",
    "We will be exploring the following adversarial attacks:\n",
    " * PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projected Gradient Descent (PGD)\n",
    "PGD attacks are white-box attacks, specifically designed to take advantage of each layer's weight in the ML model. This attack has a parameter, `epsilon`, that attempts to find the biggest weaknesses in the model, while trying to minimize the input distortion or alteration. We exectued the PGD attack with five different values of `epsilon`.\n",
    "\n",
    "### Our Parameters\n",
    "We will be attacking three different models: an undefended model, the [vanilla Athena](https://github.com/softsys4ai/athena), and PGD-ADT. In order to effectively determine the differences in success (or, the differences in errors) between each different approach, identical parameters (i.e., identical values of epsilon) will be sent to each. This should give some experimental consistency to out data.\n",
    "\n",
    "#### The Inputs\n",
    "The parameters of epsilon for the attacks are `0.03`, `0.07`, `0.09`, `0.12`, and `0.18`. When we increase epsilon, two things will happen. The first, is that the inputs (images) will be increasingly poised to take advantage of the model's weights. The second, which occurs as an effect of the first, is that the image is increasingly distorted. This is a form of constrained optimization problem that would need to be tuned to each attack's purpose. \n",
    "\n",
    "As an example, if one was attempting to bypass the content filtering of an image upload service, the image would need to be _mostly_ recoverable. Bypassing a content filter to upload an unrecognizable image would not make much sense in practical applications.\n",
    "\n",
    "The inputs, in JSON form, looked like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_attacks': 5,\n",
       " 'configs0': {'attack': 'pgd', 'description': 'PGD_eps0.03', 'eps': 0.03},\n",
       " 'configs1': {'attack': 'pgd', 'description': 'PGD_eps0.07', 'eps': 0.07},\n",
       " 'configs2': {'attack': 'pgd', 'description': 'PGD_eps0.09', 'eps': 0.09},\n",
       " 'configs3': {'attack': 'pgd', 'description': 'PGD_eps0.12', 'eps': 0.12},\n",
       " 'configs4': {'attack': 'pgd', 'description': 'PGD_eps0.18', 'eps': 0.18}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"num_attacks\": 5,\n",
    "  \"configs0\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.03\",\n",
    "    \"eps\": 0.03\n",
    "  },\n",
    "  \"configs1\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.07\",\n",
    "    \"eps\": 0.07\n",
    "  },\n",
    "  \"configs2\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.09\",\n",
    "    \"eps\": 0.09\n",
    "  },\n",
    "  \"configs3\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.12\",\n",
    "    \"eps\": 0.12\n",
    "  },\n",
    "  \"configs4\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.18\",\n",
    "    \"eps\": 0.18\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Examples\n",
    "The results matched out hypothsis. Meaning, as the value of the tuned parameter `epsilon` increased, more distortion was created in the image, more model weights were exploited, and more errors occured.\n",
    "\n",
    "\n",
    "**Error Rates**\n",
    " * `epsilson:0.03` -> `error_rate: 0.052` (5.2%)\n",
    " * `epsilson:0.07` -> `error_rate: 0.306` (30.6%)\n",
    " * `epsilson:0.09` -> `error_rate: 0.563` (56.3%)\n",
    " * `epsilson:0.12` -> `error_rate: 0.855` (85.5%)\n",
    " * `epsilson:0.18` -> `error_rate: 1.0` (100%)\n",
    " \n",
    " \n",
    " **One Generated Image at Each Epsilion Value**\n",
    " As you can see below, as the value of epsilon increases, the recognizability of the image decreases; but, the error rate of the classifier increases.\n",
    "\n",
    "![Epsilon 0.03 Error](img/pgd_eps003_error.png)\n",
    "![Epsilon 0.07 Error](img/pgd_eps007_error.png)\n",
    "![Epsilon 0.09 Error](img/pgd_eps009_error.png)\n",
    "![Epsilon 0.12 Error](img/pgd_eps012_error.png)\n",
    "![Epsilon 0.18 Error](img/pgd_eps018_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "{'UM': 0.5539858728557013, 'Ensemble': 0.011099899091826439, 'PGD-ADT': 0.017154389505549948}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
