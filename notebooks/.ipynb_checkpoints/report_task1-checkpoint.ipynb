{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Systems Task 1\n",
    "_Daniel Jones, Praful Chunchu, Ravi Patel and Austin Staton_\n",
    "\n",
    "**Objective**: Generating adversarial attacks in the context of a zero-knowledge threat model.\n",
    "\n",
    "We will be exploring various adversarial attacks, including: _Projected Gradient Descent_, _Fast Gradient Sign Method_, and the _Basic Iterative Method_. We will be generating these adversarial examples with a specific set of tuned parameters for each attack, to also allow for a demonstration of the effectiveness of different machine learning models.\n",
    " \n",
    "### Experimental Design\n",
    "We will be attacking three different models: an undefended model, the [vanilla Athena](https://github.com/softsys4ai/athena), and PGD-ADT. \n",
    "\n",
    "In order to effectively determine the differences in success (or rather, the differences in errors) between each different approach, identical parameters will be sent to each different model, by adversarial attack. So, for any _one_ attack, (PGD, FGSM, BIM) the parameters testing the attack's efficacy will remain constistent across the three differently independant models. This does not mean that, for example, the values of inputs to attack type remains consistent for all different models. \n",
    "\n",
    "We expect this to give some experimental consistency to our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Gradient Descent (PGD)\n",
    "PGD attacks are white-box attacks, specifically designed to take advantage of each layer's weight in the ML model. This attack has a parameter, `epsilon`, that attempts to find the biggest weaknesses in the model, while trying to minimize the input distortion or alteration. We exectued the PGD attack with five different values of `epsilon`.\n",
    "\n",
    "#### The Inputs\n",
    "The parameters of epsilon for the attacks are `0.03`, `0.07`, `0.09`, `0.12`, and `0.18`. When we increase epsilon, two things will happen. The first, is that the inputs (images) will be increasingly poised to take advantage of the model's weights. The second, which occurs as an effect of the first, is that the image is increasingly distorted. This is a form of constrained optimization problem that would need to be tuned to each attack's purpose. \n",
    "\n",
    "As an example, if one was attempting to bypass the content filtering of an image upload service, the image would need to be _mostly_ recoverable. Bypassing a content filter to upload an unrecognizable image would not make much sense in practical applications.\n",
    "\n",
    "The inputs, in JSON form, looked like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_attacks': 5,\n",
       " 'configs0': {'attack': 'pgd', 'description': 'PGD_eps0.03', 'eps': 0.03},\n",
       " 'configs1': {'attack': 'pgd', 'description': 'PGD_eps0.07', 'eps': 0.07},\n",
       " 'configs2': {'attack': 'pgd', 'description': 'PGD_eps0.09', 'eps': 0.09},\n",
       " 'configs3': {'attack': 'pgd', 'description': 'PGD_eps0.12', 'eps': 0.12},\n",
       " 'configs4': {'attack': 'pgd', 'description': 'PGD_eps0.18', 'eps': 0.18}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"num_attacks\": 5,\n",
    "  \"configs0\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.03\",\n",
    "    \"eps\": 0.03\n",
    "  },\n",
    "  \"configs1\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.07\",\n",
    "    \"eps\": 0.07\n",
    "  },\n",
    "  \"configs2\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.09\",\n",
    "    \"eps\": 0.09\n",
    "  },\n",
    "  \"configs3\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.12\",\n",
    "    \"eps\": 0.12\n",
    "  },\n",
    "  \"configs4\": {\n",
    "    \"attack\": \"pgd\",\n",
    "    \"description\": \"PGD_eps0.18\",\n",
    "    \"eps\": 0.18\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Examples\n",
    "The results matched our hypothsis. Meaning, as the value of the tuned parameter `epsilon` increased, more distortion was created in the image, more model weights were exploited, and more errors occured.\n",
    "\n",
    "\n",
    "**Error Rates**\n",
    " * `epsilson:0.03` -> `error_rate: 0.052` (5.2%)\n",
    " * `epsilson:0.07` -> `error_rate: 0.306` (30.6%)\n",
    " * `epsilson:0.09` -> `error_rate: 0.563` (56.3%)\n",
    " * `epsilson:0.12` -> `error_rate: 0.855` (85.5%)\n",
    " * `epsilson:0.18` -> `error_rate: 1.0` (100%)\n",
    " \n",
    " \n",
    " **One Generated Image at Each Epsilion Value**\n",
    " As you can see below, as the value of epsilon increases, the recognizability of the image decreases; but, the error rate of the classifier increases.\n",
    "\n",
    "![Epsilon 0.03 Error](img/pgd_eps003_error.png)\n",
    "![Epsilon 0.07 Error](img/pgd_eps007_error.png)\n",
    "![Epsilon 0.09 Error](img/pgd_eps009_error.png)\n",
    "![Epsilon 0.12 Error](img/pgd_eps012_error.png)\n",
    "![Epsilon 0.18 Error](img/pgd_eps018_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Evaluated Models\n",
    "| **Epsilon** | **Undefended Model** | **Ensemble of WDs** | **PGD-ADT**|\n",
    "|:---------:|:------------:|:---------:|:------------:|\n",
    "| x | 0.04137235116044399 | 0.0030272452068617556 | 0.006054490413723511 |\n",
    "| x | 0.2956609485368315 | 0.007063572149344097 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Gradient Signed Method (FGSM)\n",
    "FGSM adversarial attacks are white-box attacks that exploit the gradients, or parameters, to a neural network. It is designed to prioritize speed, rather than designed around solving the constrained optimization problem between data integrity and perturbation, like PGD.\n",
    "\n",
    "FGSM uses the sign of loss function (what is somewhat similar to the linear \"direction\" to the next classification) to determine where the model could easiest misrepresent the data, moves in a \"distance\" of `epsilon` to that next space within the network. \n",
    "\n",
    "With this vector, having a direction (the sign of a loss function) and magnitude (epsilon) can be used to fool a classifier. \n",
    "\n",
    "#### The Inputs\n",
    "The parameters of epsilon (i.e., distance) for the FGSM  attacks are: `0.1`, `0.5`, `0.7`, `0.8`, and `0.9`. `epsilon` in FGSM is paired as a scalar value to determine how much pertubation to create in the classification.\n",
    "\n",
    "The inputs, in JSON form, looked like the below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"num_attacks\": 5,\n",
    "  \"configs0\": {\n",
    "    \"attack\": \"fgsm\",\n",
    "    \"description\": \"fgsm_eps0.1\",\n",
    "    \"eps\": 0.1\n",
    "  },\n",
    "  \"configs1\": {\n",
    "    \"attack\": \"fgsm\",\n",
    "    \"description\": \"fgsm_eps0.5\",\n",
    "    \"eps\": 0.5\n",
    "  },\n",
    "  \"configs2\": {\n",
    "    \"attack\": \"fgsm\",\n",
    "    \"description\": \"fgsm_eps0.7\",\n",
    "    \"eps\": 0.7\n",
    "  },\n",
    "  \"configs3\": {\n",
    "    \"attack\": \"fgsm\",\n",
    "    \"description\": \"fgsm_eps0.8\",\n",
    "    \"eps\": 0.8\n",
    "  },\n",
    "  \"configs4\": {\n",
    "    \"attack\": \"fgsm\",\n",
    "    \"description\": \"fgsm_eps0.9\",\n",
    "    \"eps\": 0.9\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Examples\n",
    "The results matched our hypothsis. Meaning, as the value of the tuned parameter `epsilon` increased, the 'distance' away from the original classification changed.\n",
    "\n",
    "**Error Rates**\n",
    " * `epsilson:0.1` -> `error_rate: 0.273` (27.3%)\n",
    " * `epsilson:0.5` -> `error_rate: 0.904` (90.4%)\n",
    " * `epsilson:0.7` -> `error_rate: 0.906` (90.6%)\n",
    " * `epsilson:0.8` -> `error_rate: 0.917` (91.7%)\n",
    " * `epsilson:0.9` -> `error_rate: 0.908` (90.8%)\n",
    " \n",
    " \n",
    "**One Generated Image at Each Epsilion Value**\n",
    "\n",
    "As you can see below, as the value of epsilon increases, the recognizability of the image decreases; but, the error rate of the classifier increases.\n",
    "\n",
    "![Epsilon 0.1 Error](img/fgsm_eps01.png)\n",
    "![Epsilon 0.5 Error](img/fgsm_eps0.5.png)\n",
    "![Epsilon 0.7 Error](img/fgsm_eps07.png)\n",
    "![Epsilon 0.8 Error](img/fgsm_eps08.png)\n",
    "![Epsilon 0.9 Error](img/fgsm_eps09.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM Eval_Model Results\n",
    "{'UM': 0.8990918264379415, 'Ensemble': 0.8940464177598385, 'PGD-ADT': 0.8809283551967709}\n",
    "\n",
    "| **Un** | **** | **** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Iteractive Method (BIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"num_attacks\": 5,\n",
    "  \"configs0\": {\n",
    "    \"attack\": \"bim\",\n",
    "    \"description\": \"bim_eps0.9iter100\",\n",
    "    \"eps\": 0.9,\n",
    "    \"max_iter\": 100\n",
    "  },\n",
    "  \"configs1\": {\n",
    "    \"attack\": \"bim\",\n",
    "    \"description\": \"bim_eps0.4iter75\",\n",
    "    \"eps\": 0.4,\n",
    "    \"max_iter\": 75\n",
    "  },\n",
    "  \"configs2\": {\n",
    "    \"attack\": \"bim\",\n",
    "    \"description\": \"bim_eps0.01ter100\",\n",
    "    \"eps\": 0.01,\n",
    "    \"max_iter\": 100\n",
    "  },\n",
    "  \"configs3\": {\n",
    "    \"attack\": \"bim\",\n",
    "    \"description\": \"bim_eps0.9iter40\",\n",
    "    \"eps\": 0.9,\n",
    "    \"max_iter\": 40\n",
    "  },\n",
    "  \"configs4\": {\n",
    "    \"attack\": \"bim\",\n",
    "    \"description\": \"bim_eps0.6iter25\",\n",
    "    \"eps\": 0.6,\n",
    "    \"max_iter\": 25\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Examples\n",
    "The results matched out hypothsis. Meaning, as the value of the tuned parameter `epsilon` increased, more distortion was created in the image, more model weights were exploited, and more errors occured.\n",
    "\n",
    "\n",
    "**Error Rates**\n",
    " * `epsilson:0.9; max_iter: 100` -> `error_rate: 1.0` (100%)\n",
    " * `epsilson:0.4; max_iter: 75` -> `error_rate: 1.0` (100%)\n",
    " * `epsilson:0.01; max_iter: 100` -> `error_rate: 0.018` (1.8%)\n",
    " * `epsilson:0.9; max_iter: 40` -> `error_rate: 1.0` (100%)\n",
    " * `epsilson:0.6; max_iter: 25` -> `error_rate: 1.0` (100%)\n",
    " \n",
    " \n",
    " **One Generated Image at Each Epsilion Value**\n",
    " As you can see below, as the value of epsilon increases, the recognizability of the image decreases; but, the error rate of the classifier increases.\n",
    "\n",
    "![Epsilon 0.9 Iter 100 Error](img/bim_eps0.9iter100.png)\n",
    "![Epsilon 0.4 Iter 75 Error](img/bim_eps0.4iter75.png)\n",
    "![Epsilon 0.01 Iter 100 Error](img/bim_eps0.01iter100.png)\n",
    "![Epsilon 0.9 Iter 40 Error](img/bim_eps0.9iter40.png)\n",
    "![Epsilon 0.6 Iter 25 Error](img/bim_eps0.6iter25.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM Eval_Model Results\n",
    "{'UM': 0.009081735620585268, 'Ensemble': 0.0030272452068617556, 'PGD-ADT': 0.005045408678102927}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval_Model Results when evaluating against all 15 adversarial examples generated\n",
    "\n",
    "{'UM': 0.009081735620585268, 'Ensemble': 0.0030272452068617556, 'PGD-ADT': 0.005045408678102927}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
